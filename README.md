# VendHub: Vending Machine Inventory Management

VendHub is a web application designed to simplify the management of vending machine sales and inventory. Users can sign up, upload sales reports from different vendors in CSV format, and view aggregated sales data for each vending machine location. The application automatically normalizes data from various sources, providing a unified dashboard for easy tracking.

## Features

* **User Authentication**: Secure sign-up and login functionality using Supabase Auth.
* **Sales Dashboard**: A central dashboard that displays all unique vending machine locations derived from sales data.
* **Detailed Location View**: Click on any location to see a detailed history of all product sales, including dates, product names, prices, and totals.
* **CSV Upload and Processing**: Easily upload sales reports. The backend is designed to handle different CSV column structures from multiple vendors.
* **Data Normalization**: Intelligently maps and cleans data from uploaded files into a standardized format for the database.
* **Responsive UI**: Built with Material-UI for a clean, modern, and responsive user experience on any device.

## Tech Stack

* **Framework**: [Next.js](https://nextjs.org/)
* **Backend & Database**: [Supabase](https://supabase.io/)
* **Styling**: [Material-UI (MUI)](https://mui.com/) & [Tailwind CSS](https://tailwindcss.com/)
* **CSV Parsing**: [Papa Parse](https://www.papaparse.com/)
* **Notifications**: [React Hot Toast](https://react-hot-toast.com/)
* **Date Handling**: [date-fns](https://date-fns.org/)

## Getting Started

Follow these instructions to get a local copy of the project up and running for development and testing purposes.

### Prerequisites

* Node.js (v18.18 or later)
* npm, yarn, or pnpm
* A free [Supabase](https://supabase.com/) account

### Installation & Setup

1.  **Clone the repository:**
    ```bash
    git clone <your-repository-url>
    cd <repository-directory>
    ```

2.  **Install dependencies:**
    ```bash
    npm install
    ```

3.  **Set up Supabase:**
    * Go to your Supabase dashboard and create a new project.
    * Navigate to the **SQL Editor** and run the following commands to create the `products` table and the helper function.

        **SQL for `products` table:**
        This schema is based on the data processed in `src/app/actions.js` and queried in `src/app/dashboard/locations/[site_code]/page.jsx`.
        ```sql
        CREATE TABLE public.products (
            id bigint GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            created_at timestamp with time zone NOT NULL DEFAULT now(),
            site_code text,
            upc text,
            product_name text,
            sale_date date,
            unit_price numeric,
            final_total numeric
        );
        ```

        **SQL for `get_unique_location_site_codes` function:**
        This function is called on the main dashboard page to list the locations.
        ```sql
        CREATE OR REPLACE FUNCTION public.get_unique_location_site_codes()
        RETURNS TABLE(site_code text)
        LANGUAGE sql
        AS $$
            SELECT DISTINCT site_code FROM public.products ORDER BY site_code;
        $$;
        ```
    * In your Supabase project, navigate to **Project Settings** > **API**. Find your Project URL and your `anon` public key.

4.  **Set up environment variables:**
    * Create a new file named `.env.local` in the root of your project.
    * Add your Supabase credentials to it, as referenced in the Supabase client and server files.
        ```env
        NEXT_PUBLIC_SUPABASE_URL=YOUR_SUPABASE_PROJECT_URL
        NEXT_PUBLIC_SUPABASE_ANON_KEY=YOUR_NEXT_PUBLIC_SUPABASE_ANON_KEY
        ```

5.  **Run the development server:**
    ```bash
    npm run dev
    ```
    Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

## How It Works

The application is structured to handle sales reports from different vendors, each with potentially different CSV column names.

### Data Normalization

The core of the data import logic is in `src/lib/data/normalization.js`. It uses a mapping system to identify standard fields from a variety of possible header names.

**Supported CSV Columns (case-insensitive):**
* **Location ID**: `location_id`, `site_code`, `location`
* **Product UPC**: `scancode`, `upc`, `productid`
* **Product Name**: `product_name`, `item_description`, `product`
* **Sale Date**: `trans_date`, `sale_date`, `date` (formats `YYYY-MM-DD` and `MM/DD/YYYY` are supported)
* **Price**: `price`, `unit_price`
* **Total**: `total_amount`, `final_total`

When a file is uploaded via the `UploadForm`, the `processCsvFile` server action parses it, matches the headers to the standard fields, validates each row, and inserts the clean data into the `products` table in Supabase.

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Before deploying, make sure to set the same environment variables (`NEXT_PUBLIC_SUPABASE_URL` and `NEXT_PUBLIC_SUPABASE_ANON_KEY`) in your Vercel project settings.

Check out the [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.
